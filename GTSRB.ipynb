{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d18065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST - https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign/\n",
    "data_dir = '/Users/rytis/Desktop/EU_parama/data/GTSRB/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bcf344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(csv_path, images_dir):\n",
    "    data_dict = {}\n",
    "    regions_df = pd.read_csv(csv_path)\n",
    "    # Iterate through each row in the CSV file\n",
    "    for index, row in regions_df.iterrows():\n",
    "        img_path = f\"{images_dir}/{row['Path']}\"\n",
    "        x, y, w, h = int(row['Roi.X1']), int(row['Roi.Y1']), int(row['Width']), int(row['Height'])\n",
    "        class_label = int(row['ClassId'])\n",
    "\n",
    "        # Load the image\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        # Extract the specified region\n",
    "        region = image[y:y+h, x:x+w]\n",
    "\n",
    "        # Create a class-specific list if it doesn't exist\n",
    "        if class_label not in data_dict:\n",
    "            data_dict[class_label] = []\n",
    "\n",
    "        # Append the extracted region to the corresponding class list\n",
    "        data_dict[class_label].append(region)\n",
    "    data_dict = {k: data_dict[k] for k in sorted(data_dict)}\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc815524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# Path to the GTSRB dataset and CSV file\n",
    "train_csv_file = data_dir + 'Train.csv'\n",
    "train_dict = read_dataset(train_csv_file, data_dir)\n",
    "print(f'Training classes {len(train_dict)}')\n",
    "\n",
    "test_csv_file = data_dir + 'Test.csv'\n",
    "test_dict = read_dataset(test_csv_file, data_dir)\n",
    "print(f'Testing classes {len(train_dict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_distribution(data_dict, plot_name):\n",
    "    # Count the number of samples in each class\n",
    "    class_counts = {class_label: len(regions) for class_label, regions in data_dict.items()}\n",
    "\n",
    "    # Extract class labels and corresponding counts\n",
    "    class_labels = list(class_counts.keys())\n",
    "    class_sample_counts = list(class_counts.values())\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(class_labels, class_sample_counts)\n",
    "    plt.xlabel('Class Label')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title(f'{plot_name} Number of Samples in Each Class')\n",
    "    bars = plt.bar(class_labels, class_sample_counts)\n",
    "    # Add vertical counts on the bars\n",
    "    for bar, count in zip(bars, class_sample_counts):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, 30, count, ha='center', va='bottom', rotation='vertical')\n",
    "    plt.xticks(class_labels)\n",
    "    # Add grid lines in x and y directions\n",
    "    plt.grid(True, axis='both', linestyle='--', alpha=0.6)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cee57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_distribution(train_dict, 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3535352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_distribution(test_dict, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf544982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show few sample of each dataset\n",
    "# Display a few sample images from each class\n",
    "def preview_dataset(class_regions):\n",
    "    num_samples_to_display = 3 \n",
    "    for class_label, regions in class_regions.items():\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.suptitle(f'Sample Images for Class {class_label}')\n",
    "        for i in range(num_samples_to_display):\n",
    "            plt.subplot(1, num_samples_to_display, i + 1)\n",
    "            random_region = random.choice(regions)\n",
    "            plt.imshow(cv2.cvtColor(random_region, cv2.COLOR_BGR2RGB))\n",
    "            #plt.axis('off')\n",
    "        plt.tight_layout()  # Add tight layout for subplots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbd822",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_dataset(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histograms(class_regions):\n",
    "    # Create a dictionary to store histograms for each class\n",
    "    class_histograms = {}\n",
    "\n",
    "    # Iterate through each class\n",
    "    for class_label, regions in class_regions.items():\n",
    "        # Initialize an empty list to store histograms for this class\n",
    "        histograms_per_channel = []\n",
    "\n",
    "        for region in regions:\n",
    "            # Calculate and store the histogram\n",
    "            pixel_count = region.size  # Calculate pixel count\n",
    "            histogram = np.array([cv2.calcHist([region], [channel], None, [256], [0, 256])\n",
    "                                  for channel in range(3)]) / pixel_count # Separate histograms for Red, Green, and Blue\n",
    "            histograms_per_channel.append(histogram)  # Divide histogram values by pixel count\n",
    "        # Compute the average histogram for the class\n",
    "        average_histogram = np.mean(np.array(histograms_per_channel), axis=0)\n",
    "        # Store the average histogram\n",
    "        class_histograms[class_label] = average_histogram\n",
    "        \n",
    "    return class_histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d78bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes_histograms = get_histograms(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b3687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_channel_histograms_for_class(class_label, histograms):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(f'RGB Histogram for Class {class_label}')\n",
    "    plt.xlabel('Pixel Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlim([0, 256])\n",
    "    plt.plot(histograms[2, :], color='red', label='Red Channel')\n",
    "    plt.plot(histograms[1, :], color='green', label='Green Channel')\n",
    "    plt.plot(histograms[0, :], color='blue', label='Blue Channel')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d5389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram for each class\n",
    "for class_id, histogram in train_classes_histograms.items():\n",
    "    plot_channel_histograms_for_class(class_id, np.squeeze(histogram))\n",
    "    print(histogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116f0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a95b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = data_dir\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af66dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap='viridis')\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_show = []\n",
    "titles_show = []\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_show.append(x_train[r])\n",
    "    titles_show.append('training image [' + str(r) + '] = ' + str(y_train[r]))    \n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_show.append(x_test[r])        \n",
    "    titles_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "show_images(images_show, titles_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(subset_name, class_counts, class_labels):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Add grid lines on x, y\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Create a bar plot\n",
    "    bars = plt.bar(class_labels, class_counts)\n",
    "\n",
    "    # Add count text on top of the bars\n",
    "    for bar, count in zip(bars, class_counts):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, count, str(count),\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "    plt.xticks(class_labels)\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"{subset_name} class distribution\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1361eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution for train subset\n",
    "train_class_counts = np.bincount(y_train)\n",
    "train_class_labels = np.unique(y_train)\n",
    "plot_distribution('Train', train_class_counts, train_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5addc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution for test subset\n",
    "test_class_counts = np.bincount(y_test)\n",
    "test_class_labels = np.unique(y_test)\n",
    "plot_distribution('Test', test_class_counts, test_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff0ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature analysis (pixel intensity distribution for the whole dataset)\n",
    "def draw_pixel_distribution(subset_name, data, grouping=30):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(data, bins=grouping, range=(0, 256))\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"{subset_name} pixel intensity distribution [bins={grouping}]\")\n",
    "    # Add grid lines on x, y\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ea581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast list of list to np.array\n",
    "x_train = [np.array(sublist) for sublist in x_train]\n",
    "x_test = [np.array(sublist) for sublist in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw pixel distribution for train\n",
    "draw_pixel_distribution('Train', np.concatenate(x_train).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw pixel distribution for test\n",
    "draw_pixel_distribution('Test', np.concatenate(x_test).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolation forest for abnormality in histogram\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out classes one by one\n",
    "desired_class = 6\n",
    "# find indices where the value occurs\n",
    "indices = [i for i, x in enumerate(y_train) if x == desired_class]\n",
    "# get values of these classes\n",
    "desired_class_x = [x_train[i] for i in indices]\n",
    "# create list with annotations\n",
    "desired_class_y = [desired_class] * len(desired_class_x)\n",
    "# show few elements\n",
    "images_show = []\n",
    "titles_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, len(desired_class_x))\n",
    "    images_show.append(desired_class_x[r])\n",
    "    titles_show.append('Class ' + str(desired_class_y[r]) + ' training image [' + str(r) + '] = ' + str(desired_class_y[r])) \n",
    "    \n",
    "show_images(images_show, titles_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select defined number of image and introduce noise in the digits\n",
    "noisy_image_count = 5\n",
    "indices_for_noise = random.sample(range(len(desired_class_x)), noisy_image_count)\n",
    "\n",
    "images_show = []\n",
    "titles_show = []\n",
    "\n",
    "print(f'Noisy images: {indices_for_noise}')\n",
    "for i in indices_for_noise:\n",
    "    # Create a binary mask to identify non-zero pixels\n",
    "    foreground_mask = (desired_class_x[i] > 0).astype(np.uint8)\n",
    "\n",
    "    # Define the parameters for Gaussian noise\n",
    "    mean = 1\n",
    "    stddev = 15  # Adjust this value to control the noise level\n",
    "\n",
    "    # Generate Gaussian noise for the foreground\n",
    "    noise = np.random.normal(mean, stddev, desired_class_x[i].shape).astype(np.uint8)\n",
    "    noisy_foreground = np.where(foreground_mask == 1, desired_class_x[i] + noise, 0)\n",
    "\n",
    "    # Combine the noisy foreground with the original image\n",
    "    desired_class_x[i] = np.where(foreground_mask == 1, noisy_foreground, desired_class_x[i])\n",
    "    \n",
    "    # to visualize\n",
    "    images_show.append(desired_class_x[i])\n",
    "    titles_show.append('Class ' + str(desired_class) + ' image ' + str(i))                       \n",
    "show_images(images_show, titles_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21286336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data to histogram\n",
    "bins = 30\n",
    "desired_class_x_histograms = [cv2.calcHist([image], [0], None, [bins], [0, bins]).flatten() for image in desired_class_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40697e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Isolation Forest model\n",
    "isolation_forest = IsolationForest(contamination='auto', n_estimators=1000, max_features=10, random_state=99)\n",
    "\n",
    "# Fit the model on the data\n",
    "isolation_forest.fit(desired_class_x_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the anomaly score for each data point\n",
    "anomaly_scores = isolation_forest.decision_function(desired_class_x_histograms)\n",
    "\n",
    "# Visualize the anomaly scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(anomaly_scores, bins=50, range=(-0.2, 0.2), color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Anomaly Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Anomaly Score Distribution\")\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f48bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sorting indices from the smallest (biggest anomaly)\n",
    "anomaly_score_indices = np.argsort(anomaly_scores)\n",
    "print(anomaly_score_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2092cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets print some images with most anomaly\n",
    "images_show = []\n",
    "titles_show = []\n",
    "for i in range(0, 20):\n",
    "    index = anomaly_score_indices[i]\n",
    "    images_show.append(desired_class_x[index])\n",
    "    titles_show.append('Class ' + str(desired_class) + ' image [' + str(index) + '] anomaly score = ' + \"{:.2f}\".format(round(anomaly_scores[index], 2))) \n",
    "    \n",
    "show_images(images_show, titles_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw best sample\n",
    "# lets print some images with most anomaly\n",
    "images_show = []\n",
    "titles_show = []\n",
    "for i in range(0, 20):\n",
    "    index = anomaly_score_indices[len(anomaly_score_indices)-i-1]\n",
    "    images_show.append(desired_class_x[index])\n",
    "    titles_show.append('Class ' + str(desired_class) + ' image [' + str(index) + '] anomaly score = ' + \"{:.2f}\".format(round(anomaly_scores[index], 2))) \n",
    "    \n",
    "show_images(images_show, titles_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9945b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
